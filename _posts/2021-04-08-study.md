---
layout: post
title: "Apr 8th Journal Club"
author: "Jae Eun Park (dawn2089@snu.ac.kr)"
---

    Themes: An intelligent Chatbot using deep learning with Bidirectional RNN and attention model, Emotion recognition, Speech features, Classifiers

Presenters: SB (Seoyeon Bae), HM (Hoyoung Maeng) <br>

-----------------

# Topic 1: An intelligent Chatbot using deep learning with Bidirectional RNN and attention model [SB]

### **선정 이유**

SBA 프로젝트를 진행하며 챗봇 모델링에 관심이 생겨 리뷰하게 되었다.<br>

### **내용 요약**

BRNN(Bidirectional Recurrent Neural Network) with attention 모델은 이전에 나왔던 정보 뿐만 아니라 앞으로 나오게 될 정보도 함께 고려하기 때문에 문장의 문맥, 의미, 의도 등을 추론하는 데 RNN 모델보다 훨씬 이점이 있다. BRNN 모델은 순방향과 역방향, 즉 양방향으로 시그널을 주고 받으며 각 cell에서 하나의 예측값(output)을 도출한다. attention 모델은 각 BRNN 모델의 cell에서 도출된 예측값을 attention network의 이전 단계에서 도출된 값과 더해 해당 state의 최종적인 attention value를 구한다. 연구진은 Reddit을 통해 데이터셋을 구축했으며, 전처리과정을 거쳐 데이터베이스를 생성했다. 데이터베이스는 training data와 test data로 분리했으며 전자에는 총 3,027,254개의 쌍이, 후자에는 총 5100 개의 쌍이 포함되었다. 각 문장들은 띄어쓰기와 구두점을 기준으로 토큰으로 구분되었다. 트레이닝에서는 belu score, perplexity, learning rate을 중점적으로 알아보고자 했다. 총 23,000 steps을 train 시킨 결과, 103.5시간이 소요되었으며 perplexity는 56.10, learning rate은 0.0001, bleu score는 21.67이었다. 위 결과는 타 연구와도 비교해 보았을 때, 더 나은 수치를 보여주는 것으로 예상된다. 이와 더불어, 연구진은 MacBook의 사양이 딥러닝에 적합한지를 알아보고자 하였으나, 2017년형 MacBook air는 기본적인 딥러닝 모델 training 에만 충분할 뿐, 적합하지는 않은 것으로 드러났다.<br>

### **의의**

다양한 분야에서 챗봇이 활용되고 있고, 사용자 맞춤형 챗봇의 필요성이 증가하고 있는 만큼, 실제 사람 사이 오가는 대화처럼 챗봇이 사용자의 대화 내용과 문맥을 파악하기 위해서는 BRNN 및 attention mechanism 모델이 필요하다는 것을 역설한 논문이다. 이는 추후 사용자 맞춤형 챗봇을 구현하는 다수의 연구에 많은 도움이 될 것으로 예상된다. 연구진은 본 모델이 기존의 RNN 기반 챗봇의 성능을 향상시키는 데 도움이 될 것이며 어느 domain(bank, shopping, etc)에서나 상관 없이 훈련 가능한 환경을 조성할 것으로 예상했다.<br>

### **참고 문헌**

- Dhyani, M., & Kumar, R. (2021). An intelligent Chatbot using deep learning with Bidirectional RNN and attention model. Materials Today: Proceedings, 34, 817-824. https://dx.doi.org/10.1016%2Fj.matpr.2020.05.450 <br>

# Topic 2: Emotion recognition, Speech features, Classifiers [HM] <br>

### **선정 이유**

음성 파일로부터 감정인식을 어떻게 하는지 과거의 연구결과를 학습하고 싶었으며, 특히 딥러닝을 통해 추출하는 방법론에 대하여 궁금하였다.<br>

### **내용 요약**

이 논문의 목적은 음성 처리 연구자들에게 이 분야의 기본 정보, 이론적 배경 및 현재 동향을 제공하기 위해 음성에서 감정 인식 시스템에 대한 10년간의 논문을 분석한 리뷰 논문이다. 이 논문에 따르면 음성은 음성 처리 방법으로 추출 할 수있는 보조 언어 정보와 함께 감정과 관련된 언어 정보를 전달한다. 언어 정보는 화자가 표현한 질적 패턴을 식별하는 반면, 보조 언어 정보는 일반적으로 언어 패턴 (즉, 단어 또는 구)이 발음되는 방식의 변화를 설명하는 정량적 특징을 나타낸다. 특히 (1) 사용 가능한 감정 데이터베이스 (2) 사운드 내에서의 다양한 특징 선택 방법  (3)음성 감정 인식에 사용 된 수많은 classifiers에 초점을 맞춰 리뷰가 진행 되었다. feature vector를 구분하기 위하여 크게 2가지로 분류하였는데, prosodic feature를 나타내는 LLDs(Low-Level-Descriptors) 과 statistical feature를 나타내는 functionals 로 구분하였다. 이때 prosodic feature는 pitch, energy, formants, MFCCs, LPCC 등이며, functionals는 mean, max, min, zero-crossing rate, variance 등이다.그리고 감정 인식을 위한 classifiers 는GMM, SVM, ANN, Decision tree, N-gram등이 사용되어 왔으며, 각각의 성능은 모두 다르다. 이와같이 speech 로부터 feature를 추출하고 분류하는 방법 사이에는 균일성이 부족하며, 또한 각 문화, 사람 마다 감정에 다르므로 어떠한 방법이 가장 최적의 방법인지 선언하는 것은 부적절할 것임을 나타냈었다 동시에 사람조차 혼란스러워하는 감정인식의 모호한 문제를 다루는 feature 추출과 분류 방법에 대한 더 많은 탐구와 연구가 필요하다는 것을 시사한다.<br>

### **장단점**

10년 간 출판된 논문들에 대하여 리뷰한 점에 대하여 신뢰성이 높았으며, 특히 각기 다른 분류방법과 연구내용을 크게 database, feature, classifier 3단계로 정리하여 연구들 간의 공통점과 차이점을 확인할 수 있었다. <br>
음성에 대한 특징과 딥러닝을 모두 알지 못하면 이해하기에 다소 어려운 논문 일 수 있다는 생각이 들었다. <br>

### **의의**

딥러닝의 종류에 따라 음성을 분류하는데 있어 장단점을 비교 분석하였으며, 사용가능한 database에 대해 정리한 측면이 향후 연구에 있어 많은 도움이 될 것이라고 생각한다.<br>

### **참고 문헌**

- Anagnostopoulos, C. N., Iliou, T., & Giannoukos, I. (2015). Features and classifiers for emotion recognition from speech: a survey from 2000 to 2011. Artificial Intelligence Review, 43(2), 155–177. <br>