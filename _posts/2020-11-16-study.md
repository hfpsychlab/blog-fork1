---
layout: post
title: "Nov 16th Journal Club"
author: "Soomin Cho (soominc3@illinois.edu)"
---

    Themes: Subword model, Character-level model [JP]  

Presenters: JP (Jaeun Park)<br>

-----------------

## Topic 1: Subword model, Character-level model [JP]

선정 이유: Word-level model에 이어 subword model의 필요성과 방법론에 대해 공부해보기 위해 선정하였다.<br>

내용 요약<br>
Word embedding의 유용함이 입증된 바 있으나, word-level language model을 넘어서 subword model이 더 효과적이라는 결과가 보고되고 있다. 이유는 word-level model로는 한정된 vocabulary에 대한 embedding만 얻을 수 있으며, OOV (out-of-vocabulary) 단어에 대해 대처하기 어렵기 때문이다. subword model은 morphology가 복잡한 언어들을 다룰 때, informal spelling을 가진 단어를 다룰 때, 또 transliteration (음역)이 필요할 때 유리하다. Character-level model에는 character embedding으로 word embedding을 만드는 방법과 언어 자체를 character 단위로 처리하는 방법, 두 가지 방법이 있으며 두 방법 모두 성공적인 것으로 알려져 있다. 대표적인 subword model로 Byte Pair Encoding (BPE)이 있다. BPE는 각 단어의 Unicode character부터 시작해서 가장 빈번히 등장하는 ngram pair를 만들어나가는 방식인데, 매우 효과적이고 널리 사용되고 있다. 이와 같이 단어로부터 subword embedding을 만드는 방식 외에도 word embedding을 주로 사용하되 OOV에 대해서만 character level을 사용하는 hybrid model 등 다양한 방식을 채택할 수 있다.<br>

의의: subword model은 word-level model에 비해 한국어와 같은 형태학적으로 복잡한 언어와 각종 OOV에 대해 더 잘 대처할 수 있다.  

<br>
