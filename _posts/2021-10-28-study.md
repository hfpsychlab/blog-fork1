---
layout: post
title: "Oct 28th Journal Club"
author: "Jae Eun Park (dawn2089@snu.ac.kr)"
---

    Themes: Human-level bond, Woebot, Conversational Agent, Self-Talk, Implicit Commonsense Knowledge for Response Generation 
    
Presenters: YK (Yoon Kyung Lee), SB (Seoyeon Bae)  <br>


-----------------

# Topic 1: Human-level bond, Woebot, Conversational Agent [YK]

### **선정 이유**

우봇을 만든 회사에서 새로 선보인 페이퍼.
우봇을 실제로 사용해본 사람들의 평가 뿐만 아니라 우울과 불안을 경감하는 효과가 있었는지 궁금헸다.

### **내용**
실제 본문은 3페이지 정도의 아주 간결한 페이퍼다. 기존의 대면 방식의 상담과 인터넷 기반 일방향 상담 위주로 우봇을 비교했다. 생각보다 선례가 많이 없어서 의외였다.
"치료"의 영역에 들어올 수 있는 또는 그렇게 간주할 수 있는 상담 사례를 선정하는 것, 그 기준이 모호해서일 수 있다.
다 합쳐서 10개가 되지않는 다는 것이 우봇의 효과 검증에 대한 타당성을 논하기엔 아직 부족한 것 같다.
하지만 샘플이 3만명 이상이며 기존의 대면 상담에 비해 5주 이상 단축된 기간동안 간단한 감정 진단 및 대화를 함으로써써어느정도 
우울과 불안 경감 효과를 보았다는 것이 인상적이다. 하지만 이도 이 연구팀에서 우봇에만 적용되는 작업 동맹 척도를 개발하여
측정한 결과만을 보고했기에 기존의 인재행동, 우울, 불안을 측정하는데 쓰인 검사에서도 그 효과가 지속적으로 나타날지 궁금하다.

### **장단점**

예전에 우봇을 썼을때보다 자연어이해 성능이 더 높아진 것 같다. 논문에 나온 샘플 그램은 체리피킹한 것일 수도 있겠지만, 
간단한 대화도 가능하며 중간 중간 적절한 버튼을 써서 대화가 쑥쑥 진행될 수 있도록 기획을 한 것 같다. 완전 룰기반으로 기획되었던 초창기 모델에 비교하면
현재는 많이 발전한 하이브리드형 (룰 + 학습) 기획인 것 같다.

### **비고**
최근 국내에도 디지털 의료 학회가 출범했다. 심리 상담형 챗봇에 대한 이해를 높이고 활용 가치가 높게 만들 수 있도록 이런 연구가 더 많아졌으면 좋겠다. 

### **참고 문헌**

- Darcy, A., Daniels, J., Salinger, D., Wicks, P., & Robinson, A. (2021). Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study. JMIR Formative Research, 5(5), e27868.

# Topic 2: Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation [SB]

### **선정 이유**

챗봇 및 자연어를 사용하는 인공지능의 현존하는 가장 큰 단점 중 하나인, 맥락에 어긋나는 대화, 모순적인 대화를 해결하는 방안에 대해 관심이 있어 본 논문을 선정하게 되었다.

### **내용 요약**

사람 간의 대화에서 기본 지식(혹은 상식)을 적용하는 방식에서 착안하여, 본 연구진들은 기존의 대화 히스토리를 통해 이와 관련 있는 지식을 생성해내고, 대화 맥락 및 생성한 지식과 연관이 있는 반응도 함께 생성해내는  self-talk 모델(TBS-RG)을 고안해냈다. 대화 히스토리와 기본 지식을 연결하는 방식은 hard-matching과 soft-matching 두가지로 나누었으며, 지식 표상 방식 또한 Q&A 방식을 새로이 도입하였다. 대화 히스토리와 지식, 반응을 구분하기 위해서는 <implicit><\implicit>이라는 상징자와 prompt 두 가지 방식을 차용하였다. 모델 성능 평가 결과, TBS-RG 모델이 전통적인 RG 모델에 비해 생성 지식의 질적 측면, 지식과 출력 반응 간의 연관성, 출력 반응의 질적 측면에서 모두 우월한 것으로 밝혀졌다.

### **장단점**

장점: Self-talk 모델의 성능을 파악하기 위해 다차원적으로 평과 결과를 비교했다. 서로 다른 모델 간의 평가, 모델 내 변인들 간의 평가, 사람의 평가와 자동 평가 프로그램 간의 비교 등 다각도로 모델의 성능을 비교하고 평가하여 우수성을 검증하였다.

### **의의**

대화 히스토리에서 반응을 바로 이끌어내는 기존의 모델과 달리, 본 연구진들은 주어진 대화를 통해 직접 상식과, 상식에 기반한 response를 모두 만들어내는 self-talk 모델을 고안했다는 점에서 매우 큰 의의가 있다. 이는 현재 계속 문제시되고 있는 맥락을 벗어난, 혹은 맥락과 전혀 상관 없는 AI의 반응 출력을 추후 해결할 수 있을 것으로 예상된다.

### **참고 문헌**

- Zhou, P., Gopalakrishnan, K., Hedayatnia, B., Kim, S., Pujara, J., Ren, X., Liu, Y., & Hakkani-Tur, D. (2021). Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation. arXiv preprint arXiv:2110.08501. https://arxiv.org/abs/2110.08501
